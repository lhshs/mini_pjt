{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>전문가가 알려주는 창의 영재교육의 비법</td>\n",
       "      <td>알차네요</td>\n",
       "      <td>star star-rate5</td>\n",
       "      <td>무엇보다도 빨리들을 수 있어 좋습니다</td>\n",
       "      <td>학습지도</td>\n",
       "      <td>2023.07.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>연수로 완성하는 아이스크림 수학 교과서(4학년)</td>\n",
       "      <td>명불허전</td>\n",
       "      <td>star star-rate4</td>\n",
       "      <td>명강사라 그런지 말씀을 참 잘하시네요~</td>\n",
       "      <td>교과지도</td>\n",
       "      <td>2023.07.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>본격! 청개구리 학생심리 사로잡기</td>\n",
       "      <td>강추</td>\n",
       "      <td>star star-rate5</td>\n",
       "      <td>30년 가까이 일하면서도 놓치고 있었던 것들을 알려주었습니다. 그리고 무조건 교사 ...</td>\n",
       "      <td>학급경영</td>\n",
       "      <td>2023.07.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>가장 쉬운 수업도구, 패들렛과 띵커벨</td>\n",
       "      <td>패들렛과 띵커벨 활용 잘 할 수 있어요</td>\n",
       "      <td>star star-rate5</td>\n",
       "      <td>패들렛과 띵커벨 활용하고 있었으나 다양한 교과에 특히 독서 지도에 많이 활용 할 수...</td>\n",
       "      <td>ICT</td>\n",
       "      <td>2023.07.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>신영일과 함께하는 안전교육 365</td>\n",
       "      <td>필수 연수 부담 없이 편안하게</td>\n",
       "      <td>star star-rate4</td>\n",
       "      <td>안전 연수 올 해 꼭 받아야 하는데, 부담 없이 편안한 마음으로 마쳤어요.~</td>\n",
       "      <td>생활지도</td>\n",
       "      <td>2023.07.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5352</th>\n",
       "      <td>알베르토가 함께 하는 핵심역량 연계 다문화 교육</td>\n",
       "      <td>알베르토가 함께하는 핵심역량 연계 다문화 교육</td>\n",
       "      <td>star star-rate5</td>\n",
       "      <td>여타 연수와 다르게 새로 알게된 내용이 많이 있습니다.\\n아이들 가르치는데 많은 도...</td>\n",
       "      <td>생활지도</td>\n",
       "      <td>2022.03.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5353</th>\n",
       "      <td>전문가가 알려주는 창의 영재교육의 비법</td>\n",
       "      <td>전문가가 알려주는 창의 영재교육의 비법 연수 후기</td>\n",
       "      <td>star star-rate5</td>\n",
       "      <td>영재 교육에 대한 틀을 잡아주시는 넘 좋은 연수였습니다!\\n많은 도움이 되어 강력 ...</td>\n",
       "      <td>학습지도</td>\n",
       "      <td>2022.03.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5354</th>\n",
       "      <td>도도한 교사생활</td>\n",
       "      <td>도도한 교사생활</td>\n",
       "      <td>star star-rate5</td>\n",
       "      <td>연수를 통해 자신감을 더 갖게 되었다.</td>\n",
       "      <td>생활지도</td>\n",
       "      <td>2022.03.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5355</th>\n",
       "      <td>생각을 코딩하다! 소프트웨어교실</td>\n",
       "      <td>교실에서 활용할 수 있는 앱들 중심으로 재미있게 들었어요.</td>\n",
       "      <td>star star-rate5</td>\n",
       "      <td>교실에서 활용할 수 있는 앱들 중심으로 재미있게 들었어요.\\n코로나19로 집콕하며 ...</td>\n",
       "      <td>ICT</td>\n",
       "      <td>2022.03.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5356</th>\n",
       "      <td>누구나 쉽게 하는 캘리그라피</td>\n",
       "      <td>나도 따라하게 하는 캘리그라피 연수</td>\n",
       "      <td>star star-rate5</td>\n",
       "      <td>글씨와 그림을 힘들어하는 나도 따라하게 하는 캘리그라피 연수여서 코로나 재택치료 중...</td>\n",
       "      <td>자기계발</td>\n",
       "      <td>2022.03.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5357 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0                                 1  \\\n",
       "0          전문가가 알려주는 창의 영재교육의 비법                              알차네요   \n",
       "1     연수로 완성하는 아이스크림 수학 교과서(4학년)                              명불허전   \n",
       "2             본격! 청개구리 학생심리 사로잡기                                강추   \n",
       "3           가장 쉬운 수업도구, 패들렛과 띵커벨             패들렛과 띵커벨 활용 잘 할 수 있어요   \n",
       "4             신영일과 함께하는 안전교육 365                  필수 연수 부담 없이 편안하게   \n",
       "...                          ...                               ...   \n",
       "5352  알베르토가 함께 하는 핵심역량 연계 다문화 교육         알베르토가 함께하는 핵심역량 연계 다문화 교육   \n",
       "5353       전문가가 알려주는 창의 영재교육의 비법       전문가가 알려주는 창의 영재교육의 비법 연수 후기   \n",
       "5354                    도도한 교사생활                          도도한 교사생활   \n",
       "5355           생각을 코딩하다! 소프트웨어교실  교실에서 활용할 수 있는 앱들 중심으로 재미있게 들었어요.   \n",
       "5356             누구나 쉽게 하는 캘리그라피               나도 따라하게 하는 캘리그라피 연수   \n",
       "\n",
       "                    2                                                  3  \\\n",
       "0     star star-rate5                               무엇보다도 빨리들을 수 있어 좋습니다   \n",
       "1     star star-rate4                              명강사라 그런지 말씀을 참 잘하시네요~   \n",
       "2     star star-rate5  30년 가까이 일하면서도 놓치고 있었던 것들을 알려주었습니다. 그리고 무조건 교사 ...   \n",
       "3     star star-rate5  패들렛과 띵커벨 활용하고 있었으나 다양한 교과에 특히 독서 지도에 많이 활용 할 수...   \n",
       "4     star star-rate4         안전 연수 올 해 꼭 받아야 하는데, 부담 없이 편안한 마음으로 마쳤어요.~   \n",
       "...               ...                                                ...   \n",
       "5352  star star-rate5  여타 연수와 다르게 새로 알게된 내용이 많이 있습니다.\\n아이들 가르치는데 많은 도...   \n",
       "5353  star star-rate5  영재 교육에 대한 틀을 잡아주시는 넘 좋은 연수였습니다!\\n많은 도움이 되어 강력 ...   \n",
       "5354  star star-rate5                              연수를 통해 자신감을 더 갖게 되었다.   \n",
       "5355  star star-rate5  교실에서 활용할 수 있는 앱들 중심으로 재미있게 들었어요.\\n코로나19로 집콕하며 ...   \n",
       "5356  star star-rate5  글씨와 그림을 힘들어하는 나도 따라하게 하는 캘리그라피 연수여서 코로나 재택치료 중...   \n",
       "\n",
       "         4           5  \n",
       "0     학습지도  2023.07.28  \n",
       "1     교과지도  2023.07.28  \n",
       "2     학급경영  2023.07.28  \n",
       "3      ICT  2023.07.28  \n",
       "4     생활지도  2023.07.27  \n",
       "...    ...         ...  \n",
       "5352  생활지도  2022.03.30  \n",
       "5353  학습지도  2022.03.30  \n",
       "5354  생활지도  2022.03.30  \n",
       "5355   ICT  2022.03.30  \n",
       "5356  자기계발  2022.03.30  \n",
       "\n",
       "[5357 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/data_5474.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data (replace this with your data)\n",
    "texts = [\n",
    "    \"This is a positive sentence.\",\n",
    "    \"Another positive example.\",\n",
    "    \"Negative sentences are no good.\",\n",
    "    \"Positivity is the key.\",\n",
    "]\n",
    "\n",
    "labels = [1, 1, 0, 1]  # 1 for positive, 0 for negative (replace with your labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8326968161ce42c9bd0f841aba56f2de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hslio\\.conda\\envs\\lhs\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hslio\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002a1d941ac945d098054c5bb85ee5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5b3dd0d17c4c4fa654e9f669479a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hslio\\.conda\\envs\\lhs\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2393: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize input texts\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for text in texts:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    input_ids.append(encoded_dict[\"input_ids\"])\n",
    "    attention_masks.append(encoded_dict[\"attention_mask\"])\n",
    "\n",
    "# Convert lists to tensors\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_inputs, test_inputs, train_labels, test_labels = train_test_split(\n",
    "    input_ids, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_masks, test_masks, _, _ = train_test_split(\n",
    "    attention_masks, input_ids, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataLoader for efficient batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size and create DataLoader\n",
    "batch_size = 32\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune BERT for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8d6801057c4404819273a8c085c570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.8662\n",
      "Epoch 2/3, Loss: 0.9342\n",
      "Epoch 3/3, Loss: 0.7230\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       0.0\n",
      "           1       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       1.0\n",
      "   macro avg       0.00      0.00      0.00       1.0\n",
      "weighted avg       0.00      0.00      0.00       1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hslio\\.conda\\envs\\lhs\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\hslio\\.conda\\envs\\lhs\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\hslio\\.conda\\envs\\lhs\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\hslio\\.conda\\envs\\lhs\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\hslio\\.conda\\envs\\lhs\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\hslio\\.conda\\envs\\lhs\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "# Set the device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs, masks, labels = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, attention_mask=masks)[0]\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs, masks, labels = batch\n",
    "\n",
    "        outputs = model(inputs, attention_mask=masks)[0]\n",
    "        _, pred_labels = torch.max(outputs, dim=1)\n",
    "\n",
    "        predictions.extend(pred_labels.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "print(classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
