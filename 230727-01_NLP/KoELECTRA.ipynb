{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/monologg/KoELECTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ice_data ='https://raw.githubusercontent.com/lhshs/mydataset/main/genia/2307_NLP/ice_model.csv'\n",
    "# tsh_data = 'https://raw.githubusercontent.com/lhshs/mydataset/main/genia/2307_NLP/tsh_model.csv'\n",
    "# ice = pd.read_csv(ice_data, index_col=0)\n",
    "# tsh = pd.read_csv(ice_data, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ice = pd.read_csv('data/icecream_emot.csv')\n",
    "tsh = pd.read_csv('data/sherpa_emot3.csv')\n",
    "\n",
    "tsh = tsh[['title_comments', 'star']]\n",
    "tsh.rename(columns={'title_comments' : 'text', 'star' : 'score'}, inplace=True)\n",
    "tsh['score'] = tsh['score'].apply(lambda x : int(x.replace('점','')))\n",
    "tsh['score'] = tsh['score'].apply(lambda x : 0 if x == 3 else (1 if x > 3 else -1))\n",
    "\n",
    "ice = ice[['title_comments', 'rated']]\n",
    "ice.rename(columns={'title_comments' : 'text', 'rated' : 'score'}, inplace=True)\n",
    "ice['score'] = ice['score'].apply(lambda x : int(x[-1]))\n",
    "ice['score'] = ice['score'].apply(lambda x : 0 if x == 3 else (1 if x > 3 else -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>알차네요 무엇보다도 빨리들을 수 있어 좋습니다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>명불허전 명강사라 그런지 말씀을 참 잘하시네요~</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>강추 30년 가까이 일하면서도 놓치고 있었던 것들을 알려주었습니다. 그리고 무조건 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>패들렛과 띵커벨 활용 잘 할 수 있어요 패들렛과 띵커벨 활용하고 있었으나 다양한 교...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>필수 연수 부담 없이 편안하게 안전 연수 올 해 꼭 받아야 하는데, 부담 없이 편안...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5236</th>\n",
       "      <td>알베르토가 함께하는 핵심역량 연계 다문화 교육 여타 연수와 다르게 새로 알게된 내용...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237</th>\n",
       "      <td>전문가가 알려주는 창의 영재교육의 비법 연수 후기 영재 교육에 대한 틀을 잡아주시는...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5238</th>\n",
       "      <td>도도한 교사생활 연수를 통해 자신감을 더 갖게 되었다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5239</th>\n",
       "      <td>교실에서 활용할 수 있는 앱들 중심으로 재미있게 들었어요. 교실에서 활용할 수 있는...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5240</th>\n",
       "      <td>나도 따라하게 하는 캘리그라피 연수 글씨와 그림을 힘들어하는 나도 따라하게 하는 캘...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5241 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  score\n",
       "0                             알차네요 무엇보다도 빨리들을 수 있어 좋습니다      1\n",
       "1                            명불허전 명강사라 그런지 말씀을 참 잘하시네요~      1\n",
       "2     강추 30년 가까이 일하면서도 놓치고 있었던 것들을 알려주었습니다. 그리고 무조건 ...      1\n",
       "3     패들렛과 띵커벨 활용 잘 할 수 있어요 패들렛과 띵커벨 활용하고 있었으나 다양한 교...      1\n",
       "4     필수 연수 부담 없이 편안하게 안전 연수 올 해 꼭 받아야 하는데, 부담 없이 편안...      1\n",
       "...                                                 ...    ...\n",
       "5236  알베르토가 함께하는 핵심역량 연계 다문화 교육 여타 연수와 다르게 새로 알게된 내용...      1\n",
       "5237  전문가가 알려주는 창의 영재교육의 비법 연수 후기 영재 교육에 대한 틀을 잡아주시는...      1\n",
       "5238                     도도한 교사생활 연수를 통해 자신감을 더 갖게 되었다.      1\n",
       "5239  교실에서 활용할 수 있는 앱들 중심으로 재미있게 들었어요. 교실에서 활용할 수 있는...      1\n",
       "5240  나도 따라하게 하는 캘리그라피 연수 글씨와 그림을 힘들어하는 나도 따라하게 하는 캘...      1\n",
       "\n",
       "[5241 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ice modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\u001b[95mjaehyeong/koelectra-base-v3-generalized-sentiment-analysis\u001b[0m=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\hslio\\AppData\\Local\\Temp\\ipykernel_5544\\1809579344.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[pre_model][idx] = '1'\n",
      "3it [00:00, 21.60it/s]C:\\Users\\hslio\\AppData\\Local\\Temp\\ipykernel_5544\\1809579344.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[pre_model][idx] = '-1'\n",
      "12it [00:00, 20.67it/s]C:\\Users\\hslio\\AppData\\Local\\Temp\\ipykernel_5544\\1809579344.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[pre_model][idx] = '0'\n",
      "5241it [04:31, 19.29it/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\u001b[95mklue/bert-base\u001b[0m=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5241it [04:24, 19.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\u001b[95mmatthewburke/korean_sentiment\u001b[0m=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5241it [03:46, 23.12it/s]\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v2-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\u001b[95mmonologg/koelectra-base-v2-discriminator\u001b[0m=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5241it [04:28, 19.51it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at skt/kogpt2-base-v2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\u001b[95mskt/kogpt2-base-v2\u001b[0m=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5241it [04:35, 19.01it/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\u001b[95mbeomi/kcbert-large\u001b[0m=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5241it [11:59,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🥕\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_lst = ['jaehyeong/koelectra-base-v3-generalized-sentiment-analysis', \n",
    "            'klue/bert-base', \n",
    "            'matthewburke/korean_sentiment',\n",
    "            # 'monologg/koelectra-base-discriminator',\n",
    "            # \"monologg/koelectra-small-discriminator\",\n",
    "            \"monologg/koelectra-base-v2-discriminator\",\n",
    "            # \"monologg/koelectra-small-v2-discriminator\",\n",
    "            # \"monologg/koelectra-base-v3-discriminator\",\n",
    "            # \"monologg/koelectra-small-v3-discriminator\",\n",
    "            # \"facebook/bart-large-mnli\",\n",
    "            # \"monologg/koelectra-base-v3-goemotions\",\n",
    "            'skt/kogpt2-base-v2',\n",
    "            # 'skt/kobert-base-v1',\n",
    "            'beomi/kcbert-large',\n",
    "            # \"google/electra-small-discriminator\"\n",
    "            ]\n",
    "\n",
    "\n",
    "for i in model_lst: # 0,1,2,3\n",
    "    # load model\n",
    "    pre_model = i\n",
    "    tokenizer = AutoTokenizer.from_pretrained(pre_model)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(pre_model)\n",
    "    sentiment_classifier = TextClassificationPipeline(tokenizer=tokenizer, model=model)\n",
    "\n",
    "    print('====='+ '\\033[95m' + pre_model + '\\033[0m' + '=====')\n",
    "\n",
    "    # target reviews\n",
    "    review_list = list(ice.text)\n",
    "\n",
    "    ice[pre_model] = '-'\n",
    "    # predict\n",
    "    for idx, review in tqdm(enumerate(review_list)):\n",
    "        pred = sentiment_classifier(review)\n",
    "        # print(f'{review}\\n>> {pred[0]}')\n",
    "        if ((pred[0]['label']=='1')&(pred[0]['score']>0.7)) | ((pred[0]['label']=='LABEL_1')&(pred[0]['score']>0.7)):\n",
    "            ice[pre_model][idx] = '1'\n",
    "        elif ((pred[0]['label']=='0')&(pred[0]['score']>0.7)) | ((pred[0]['label']=='LABEL_0')&(pred[0]['score']>0.7)):  \n",
    "            ice[pre_model][idx] = '-1'\n",
    "        else:\n",
    "            ice[pre_model][idx] = '0'\n",
    "\n",
    "        # print(f'{review}\\n>> {pred[0]}')\n",
    "\n",
    "print('🥕')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유익한 연수였습니다. 유익한 연수였습니다.                                                                                                                                                                        11\n",
      "추천합니다, 추천합니다,                                                                                                                                                                                   7\n",
      "많은 도움이 되었습니다 ^^ 많은 도움이 되었습니다 ^^                                                                                                                                                                 6\n",
      "연수시간,,, 좋아요!! 괜찮네요 연수시간,,, 좋아요!! 괜찮네요                                                                                                                                                           6\n",
      "추천합니다. 유용한 강좌입니다. 추천합니다.                                                                                                                                                                        5\n",
      "                                                                                                                                                                                               ..\n",
      "생각보다는 쉬운 연수 중등 영어교사가 듣기에는 매우 쉬운 수준이라,\\n조금 아쉬웠어요\\n하지만 중간 중간 헷갈리는 발음이나 단어 사용 팁을 짚어주는 것은\\n매우 유용했습니다.\\n다만, 연수 제목처럼 네셔널지오그래픽의 많은 내용이 인용될 줄 알았는데\\n그것보다는 반복이 중심이 되서 핵심 어구를 짚어주는 게 메인이라\\n아쉬웠습니다..!!     1\n",
      "지루함없이 너무 재밌고 실생활에 적용 가능하여 참 좋네요. 두 분의 조합도 너무 좋고 아이들 동아리 때 반을 개설하여 만들기에도 너무 적합하고 진짜 딱인 것 같네요.\\n이렇게 알찬 연수는 언제나 환영입니다.                                                                             1\n",
      "즐거운 연수였습니다 디지털 드로잉에 대해 잘 알아볼 수 있어서 너무 유익한 연수였습니다.                                                                                                                                               1\n",
      "요새 구글에 대해 잘 알고 있어야 하는데 구글에 대해 잘 이해할 수 있는 유익한 연수였습니다.\\n다양한 것들을 잘 활용해 보아야 겠습니다.                                                                                                                   1\n",
      "나도 따라하게 하는 캘리그라피 연수 글씨와 그림을 힘들어하는 나도 따라하게 하는 캘리그라피 연수여서 코로나 재택치료 중에 중독된 듯 따라 연습했습니다. 강사님의 명쾌한 설명과 어려지 않게 지도하는 내용으로 5일 내내 이 연수들으면서 연습했습니다. 드디어 내일 출근합니다.\\n현장 선생님들, 팟팅!!!                         1\n",
      "Name: text, Length: 5159, dtype: int64\n",
      " 1    5146\n",
      " 0      64\n",
      "-1      31\n",
      "Name: score, dtype: int64\n",
      "1     5100\n",
      "-1      77\n",
      "0       64\n",
      "Name: jaehyeong/koelectra-base-v3-generalized-sentiment-analysis, dtype: int64\n",
      "0     5230\n",
      "-1       9\n",
      "1        2\n",
      "Name: klue/bert-base, dtype: int64\n",
      "1     5108\n",
      "0       68\n",
      "-1      65\n",
      "Name: matthewburke/korean_sentiment, dtype: int64\n",
      "0    5241\n",
      "Name: monologg/koelectra-base-v2-discriminator, dtype: int64\n",
      "0     5182\n",
      "-1      59\n",
      "Name: skt/kogpt2-base-v2, dtype: int64\n",
      "0     5064\n",
      "1      172\n",
      "-1       5\n",
      "Name: beomi/kcbert-large, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in ice.iloc[:, :].columns:\n",
    "    print(ice[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ice.to_csv('ice_model.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tsh modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\u001b[95mjaehyeong/koelectra-base-v3-generalized-sentiment-analysis\u001b[0m=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\hslio\\AppData\\Local\\Temp\\ipykernel_6608\\1483638988.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tsh[pre_model][idx] = '1'\n",
      "6it [00:00, 13.22it/s]C:\\Users\\hslio\\AppData\\Local\\Temp\\ipykernel_6608\\1483638988.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tsh[pre_model][idx] = '-1'\n",
      "68it [00:03, 16.04it/s]C:\\Users\\hslio\\AppData\\Local\\Temp\\ipykernel_6608\\1483638988.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tsh[pre_model][idx] = '0'\n",
      "2600it [02:31, 17.12it/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\u001b[95mklue/bert-base\u001b[0m=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\hslio\\AppData\\Local\\Temp\\ipykernel_6608\\1483638988.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tsh[pre_model][idx] = '0'\n",
      "2600it [02:29, 17.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\u001b[95mmatthewburke/korean_sentiment\u001b[0m=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\hslio\\AppData\\Local\\Temp\\ipykernel_6608\\1483638988.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tsh[pre_model][idx] = '1'\n",
      "6it [00:00, 16.68it/s]C:\\Users\\hslio\\AppData\\Local\\Temp\\ipykernel_6608\\1483638988.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tsh[pre_model][idx] = '-1'\n",
      "281it [00:11, 18.07it/s]C:\\Users\\hslio\\AppData\\Local\\Temp\\ipykernel_6608\\1483638988.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tsh[pre_model][idx] = '0'\n",
      "2600it [02:06, 20.53it/s]\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v2-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\u001b[95mmonologg/koelectra-base-v2-discriminator\u001b[0m=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\hslio\\AppData\\Local\\Temp\\ipykernel_6608\\1483638988.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tsh[pre_model][idx] = '0'\n",
      "2600it [03:37, 11.96it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at skt/kogpt2-base-v2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\u001b[95mskt/kogpt2-base-v2\u001b[0m=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\hslio\\AppData\\Local\\Temp\\ipykernel_6608\\1483638988.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tsh[pre_model][idx] = '0'\n",
      "6it [00:00, 11.57it/s]C:\\Users\\hslio\\AppData\\Local\\Temp\\ipykernel_6608\\1483638988.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tsh[pre_model][idx] = '-1'\n",
      "2600it [02:48, 15.46it/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-large and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\u001b[95mbeomi/kcbert-large\u001b[0m=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\hslio\\AppData\\Local\\Temp\\ipykernel_6608\\1483638988.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tsh[pre_model][idx] = '0'\n",
      "53it [00:06, 11.29it/s]C:\\Users\\hslio\\AppData\\Local\\Temp\\ipykernel_6608\\1483638988.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tsh[pre_model][idx] = '-1'\n",
      "2600it [06:53,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🥕\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_lst = ['jaehyeong/koelectra-base-v3-generalized-sentiment-analysis', \n",
    "            'klue/bert-base', \n",
    "            'matthewburke/korean_sentiment',\n",
    "            # 'monologg/koelectra-base-discriminator',\n",
    "            # \"monologg/koelectra-small-discriminator\",\n",
    "            \"monologg/koelectra-base-v2-discriminator\",\n",
    "            # \"monologg/koelectra-small-v2-discriminator\",\n",
    "            # \"monologg/koelectra-base-v3-discriminator\",\n",
    "            # \"monologg/koelectra-small-v3-discriminator\",\n",
    "            # \"facebook/bart-large-mnli\",\n",
    "            # \"monologg/koelectra-base-v3-goemotions\",\n",
    "            'skt/kogpt2-base-v2',\n",
    "            # 'skt/kobert-base-v1',\n",
    "            'beomi/kcbert-large',\n",
    "            # \"google/electra-small-discriminator\"\n",
    "            ]\n",
    "\n",
    "\n",
    "for i in model_lst: # 0,1,2,3\n",
    "    # load model\n",
    "    pre_model = i\n",
    "    tokenizer = AutoTokenizer.from_pretrained(pre_model)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(pre_model)\n",
    "    sentiment_classifier = TextClassificationPipeline(tokenizer=tokenizer, model=model)\n",
    "\n",
    "    print('====='+ '\\033[95m' + pre_model + '\\033[0m' + '=====')\n",
    "\n",
    "    # target reviews\n",
    "    review_list = list(tsh.text)\n",
    "\n",
    "    tsh[pre_model] = '-'\n",
    "    # predict\n",
    "    for idx, review in tqdm(enumerate(review_list)):\n",
    "        pred = sentiment_classifier(review)\n",
    "        # print(f'{review}\\n>> {pred[0]}')\n",
    "        if (pred[0]['label']=='1')&(pred[0]['score'] > 0.7) | (pred[0]['label']=='LABEL_1')&(pred[0]['score'] > 0.7):\n",
    "            tsh[pre_model][idx] = '1'\n",
    "        elif (pred[0]['label']=='0')&(pred[0]['score']>0.7) | (pred[0]['label']=='LABEL_0')&(pred[0]['score'] > 0.7):  \n",
    "            tsh[pre_model][idx] = '-1'\n",
    "        else:\n",
    "            tsh[pre_model][idx] = '0'\n",
    "\n",
    "        # print(f'{review}\\n>> {pred[0]}')\n",
    "\n",
    "print('🥕')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text                                                                                                                                                                                                                                            \n",
      "정말 좋네요! 정말 좋네요!                                                                                                                                                                                                                                     7\n",
      "최고에요! 최고에요!                                                                                                                                                                                                                                         6\n",
      "좋아요~ 좋아요~                                                                                                                                                                                                                                           5\n",
      "좋아용 연수 추천합니다 좋아용 연수 추천합니다                                                                                                                                                                                                                           4\n",
      "좋아요 좋아요                                                                                                                                                                                                                                             4\n",
      "                                                                                                                                                                                                                                                   ..\n",
      "박물관 여행 연수 후기 박물관이 이렇게 많이 있는 줄 몰랐습니다.\\n박물관에 대해 자세히 알 수 있어서 좋았습니다.\\n방학과 주말을 이용해서 주변 박물관부터 직접 가서 느껴보고\\n전시품들의 의미를 다시 한번 새기고 싶습니니다.\\n감사합니다.                                                                                                              1\n",
      "박물관에 관심을 갖게 하는 연수 코로나로 인해 체험학습을 못해서 박물관 관람이 아쉬웠는데 이렇게 연수로나마 박물관을 느낄 수 있어서 좋았습니다. 앞으로 아이들과 만나면서 다양한 지식으로 박물관에 대해 설명할 수 있는 기회를 만들어준 유익한 연수입니다. 많은 선생님께 추천하고 싶은 연수랍니다. 감사합니다.                                                                          1\n",
      "박물관에 대한 새로운 시각 박물관이 어렵게만 느껴졌지만 가고 싶은 곳이 되는 연수였습니다. 학생들과 함께 가도 부담스럽지 않은 곳이 되는 연수가 되었습니다. 아픈 역사를 돌아보는 시간이 되는 연수이기도 했습니다. 만주주의 발자취를 따라 남산의 여러 곳을 설명을 들으면 받은 연수가 다시 떠오르는 시간이었습니다. 아픈 역사를 잊지 말고 되풀이 되지 않았으면 좋겠습니다.                                       1\n",
      "박물관을 가보고 싶게하는 연수 대부분의 강의가 설명식이었는데.. 해당 박물관에 전시된 물품을 더 자세히 보여주면 좋을 것 같습니다.\\n\\n색다른 주제의 연수라 참여했는데, 지식과 경험을 쌓을 수 있는 계기가 되었습니다. ^^                                                                                                                       1\n",
      "힘들었지만 아직도(?) 진행되는 연수 칼림바를 처음 접하고 익숙하지 않아 힘들었지만 쉽고 핵심을 짚어주는 강의에 힘을 얻어 연수를 들었습니다. 물론 진도가 나가면서 스스로 연습해야 하는 부분이 늘어남은 있었만 방학인 지금 아직도 진행되고 있는 연수라는 생각이 듭니다. 왜냐면 이 연수의 복습과 유**을 통해서 업드레이드 시키려고 계속 하게 되니까요. 요즘 칼림바를 하는 아이들이 많아져 학교에서도 아이들과 대화 주제로도 좋습니다.    1\n",
      "Length: 2558, dtype: int64\n",
      "\n",
      "score\n",
      " 1       2516\n",
      " 0         57\n",
      "-1         27\n",
      "dtype: int64\n",
      "\n",
      "jaehyeong/koelectra-base-v3-generalized-sentiment-analysis\n",
      "1                                                             2519\n",
      "-1                                                              48\n",
      "0                                                               33\n",
      "dtype: int64\n",
      "\n",
      "klue/bert-base\n",
      "0                 2600\n",
      "dtype: int64\n",
      "\n",
      "matthewburke/korean_sentiment\n",
      "1                                2526\n",
      "-1                                 49\n",
      "0                                  25\n",
      "dtype: int64\n",
      "\n",
      "monologg/koelectra-base-v2-discriminator\n",
      "0                                           2600\n",
      "dtype: int64\n",
      "\n",
      "skt/kogpt2-base-v2\n",
      "0                     2569\n",
      "-1                      31\n",
      "dtype: int64\n",
      "\n",
      "beomi/kcbert-large\n",
      "0                     2549\n",
      "-1                      51\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tsh.iloc[:, :].columns:\n",
    "    print(tsh[[i]].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>jaehyeong/koelectra-base-v3-generalized-sentiment-analysis</th>\n",
       "      <th>klue/bert-base</th>\n",
       "      <th>matthewburke/korean_sentiment</th>\n",
       "      <th>monologg/koelectra-base-v2-discriminator</th>\n",
       "      <th>skt/kogpt2-base-v2</th>\n",
       "      <th>beomi/kcbert-large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2600 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      score jaehyeong/koelectra-base-v3-generalized-sentiment-analysis  \\\n",
       "0         1                                                  1           \n",
       "1         1                                                  1           \n",
       "2         1                                                  1           \n",
       "3         1                                                  1           \n",
       "4         1                                                  1           \n",
       "...     ...                                                ...           \n",
       "2595      1                                                  1           \n",
       "2596      1                                                  1           \n",
       "2597      1                                                  0           \n",
       "2598      1                                                  1           \n",
       "2599      1                                                  1           \n",
       "\n",
       "     klue/bert-base matthewburke/korean_sentiment  \\\n",
       "0                 0                             1   \n",
       "1                 0                             1   \n",
       "2                 0                             1   \n",
       "3                 0                             1   \n",
       "4                 0                             1   \n",
       "...             ...                           ...   \n",
       "2595              0                             1   \n",
       "2596              0                             1   \n",
       "2597              0                             1   \n",
       "2598              0                             1   \n",
       "2599              0                             1   \n",
       "\n",
       "     monologg/koelectra-base-v2-discriminator skt/kogpt2-base-v2  \\\n",
       "0                                           0                  0   \n",
       "1                                           0                  0   \n",
       "2                                           0                  0   \n",
       "3                                           0                  0   \n",
       "4                                           0                  0   \n",
       "...                                       ...                ...   \n",
       "2595                                        0                  0   \n",
       "2596                                        0                  0   \n",
       "2597                                        0                  0   \n",
       "2598                                        0                  0   \n",
       "2599                                        0                  0   \n",
       "\n",
       "     beomi/kcbert-large  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "...                 ...  \n",
       "2595                 -1  \n",
       "2596                  0  \n",
       "2597                  0  \n",
       "2598                  0  \n",
       "2599                  0  \n",
       "\n",
       "[2600 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsh.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsh.to_csv('tsh_model.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
